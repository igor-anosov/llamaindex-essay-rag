<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>LlamaIndex Essay Chat</title>
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        line-height: 1.6;
      }
      .hero {
        background-color: #f8f9fa;
        padding: 3rem 0;
        border-radius: 10px;
        margin-bottom: 2rem;
      }
      .feature-icon {
        font-size: 2rem;
        margin-bottom: 1rem;
        color: #0d6efd;
      }
      pre {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 5px;
        overflow-x: auto;
      }
      .screenshot {
        border: 1px solid #dee2e6;
        border-radius: 5px;
        margin-bottom: 1rem;
        max-width: 100%;
        height: auto;
      }
    </style>
  </head>
  <body>
    <div class="container my-5">
      <div class="hero text-center p-4">
        <h1 class="display-5 fw-bold">
          RAG Chat Interface for Paul Graham's Essay
        </h1>
        <p class="lead">
          A conversational AI application that answers questions about Paul
          Graham's essay "What I Worked On"
        </p>
        <div class="d-grid gap-2 d-sm-flex justify-content-sm-center">
          <a
            href="https://github.com/igor-anosov/llamaindex-essay-rag"
            class="btn btn-primary btn-lg px-4 gap-3"
            >View on GitHub</a
          >
          <a href="#setup" class="btn btn-outline-secondary btn-lg px-4"
            >Setup Instructions</a
          >
        </div>
      </div>

      <div class="row align-items-center g-5">
        <div class="col-lg-6">
          <h2>About This Project</h2>
          <p>
            This application provides a chat interface that allows users to ask
            questions about Paul Graham's essay "What I Worked On". The system
            uses Retrieval-Augmented Generation (RAG) to provide accurate
            answers based on the content of the essay.
          </p>

          <h3>Features</h3>
          <ul>
            <li>üí¨ Interactive chat interface using Gradio</li>
            <li>üîç Semantic search using Azure OpenAI Embeddings</li>
            <li>
              ü§ñ Context-aware responses using GPT-4o through Azure OpenAI
            </li>
            <li>üìù Persistent vector index storage for faster startup</li>
            <li>üß† Memory buffer to maintain conversation context</li>
          </ul>
        </div>
        <div class="col-lg-6">
          <div class="text-center">
            <img
              src="assets/llm-essay.png"
              alt="Chat Interface Screenshot"
              class="screenshot"
            />
            <p class="text-muted">A sample interaction with the RAG system</p>
          </div>
        </div>
      </div>

      <hr class="my-5" />

      <div id="setup">
        <h2>Setup Instructions</h2>
        <p>
          This is a Python application that requires certain dependencies and
          API access. Follow these steps to run it locally:
        </p>

        <h3>Prerequisites</h3>
        <ul>
          <li>Python 3.10+ (tested with Python 3.10.13)</li>
          <li>
            Azure OpenAI API access with deployments for:
            <ul>
              <li>GPT-4o (or other chat completion model)</li>
              <li>text-embedding-ada-002 (for embeddings)</li>
            </ul>
          </li>
        </ul>

        <h3>Installation</h3>
        <ol>
          <li>
            <p>Clone the repository:</p>
            <pre><code>git clone https://github.com/igor-anosov/llamaindex-essay.git
cd llamaindex-essay</code></pre>
          </li>
          <li>
            <p>Create and activate a virtual environment:</p>
            <pre><code>python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate</code></pre>
          </li>
          <li>
            <p>Install dependencies:</p>
            <pre><code>pip install -r requirements.txt</code></pre>
          </li>
          <li>
            <p>
              Create a <code>.env</code> file with your Azure OpenAI
              credentials:
            </p>
            <pre><code>OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
OPENAI_API_VERSION=2023-05-15</code></pre>
          </li>
          <li>
            <p>Run the application:</p>
            <pre><code>python main.py</code></pre>
          </li>
          <li>
            <p>
              Open your browser at the URL shown in the terminal (typically
              http://127.0.0.1:7860)
            </p>
          </li>
        </ol>

        <div class="alert alert-info">
          <strong>Note:</strong> The first time you run the app, it will
          generate an index of the essay which may take a few moments.
          Subsequent runs will be faster as the index is stored locally.
        </div>
      </div>

      <hr class="my-5" />

      <div>
        <h2>How It Works</h2>
        <div class="row g-4">
          <div class="col-md-6">
            <h3>1. Data Ingestion</h3>
            <p>
              The system reads and processes Paul Graham's essay, splitting it
              into manageable chunks.
            </p>

            <h3>2. Embedding Generation</h3>
            <p>
              Each chunk is converted into a vector embedding using Azure
              OpenAI's embedding model.
            </p>
          </div>
          <div class="col-md-6">
            <h3>3. Query Processing</h3>
            <p>When a user asks a question, the system:</p>
            <ul>
              <li>Converts the question to an embedding</li>
              <li>Finds the most relevant chunks from the essay</li>
              <li>Sends those chunks along with the question to GPT-4o</li>
              <li>Returns the generated response to the user</li>
            </ul>

            <h3>4. Memory</h3>
            <p>
              The system maintains context of the conversation, allowing for
              follow-up questions.
            </p>
          </div>
        </div>
      </div>

      <footer class="pt-5 my-5 text-muted border-top">
        <div class="row">
          <div class="col-12 col-md">
            <small class="d-block mb-3">&copy; 2025 Igor Anosov</small>
          </div>
          <div class="col-6 col-md">
            <h5>Resources</h5>
            <ul class="list-unstyled text-small">
              <li>
                <a class="link-secondary" href="https://www.llamaindex.ai/"
                  >LlamaIndex</a
                >
              </li>
              <li>
                <a class="link-secondary" href="https://www.gradio.app/"
                  >Gradio</a
                >
              </li>
              <li>
                <a
                  class="link-secondary"
                  href="http://www.paulgraham.com/worked.html"
                  >Original Essay</a
                >
              </li>
            </ul>
          </div>
          <div class="col-6 col-md">
            <h5>About</h5>
            <ul class="list-unstyled text-small">
              <li>
                <a class="link-secondary" href="https://github.com/igor-anosov"
                  >GitHub</a
                >
              </li>
              <li>
                <a
                  class="link-secondary"
                  href="https://github.com/igor-anosov/llamaindex-essay"
                  >Project Repository</a
                >
              </li>
            </ul>
          </div>
        </div>
      </footer>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
  </body>
</html>
